---
layout: post
title: [PyTorch入门之60分钟入门闪击战]之入门
tags: [pytorch, 深度学习]
mermaid: false
math: false
---  

来源于[这里](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)。

本文目标：  

* 在高层次上理解PyTorch的Tensor库和神经网络
* 训练一个小型的图形分类神经网络  

本文示例运行在ipython中。

## 什么是PyTorch  

PyTorch是由Torch7团队开发的，从名字就可以看出，它跟Torch的不同之处在于PyTorch使用了Python作为开发语言。所谓“Python first”，同样说明它是一个以Python优先的深度学习框架，不仅能够实现强大的GPU加速，同时还支持动态神经网络。  

PyTorch既可以看做加入了GPU支持的numpy，同时也可以看成一个拥有自动求导功能的强大的深度神经网络。  

### 入门  

#### Tensor（向量）

Tensor与NumPy的ndarras类似，此外Tensor还可用于GPU加速运算。  

```python
from __future__ import print_function
import torch
```

创建一个为初始化的5x3的矩阵：  

```python
x = torch.empty(5,3)
print(x)
```

输出：  

```python
tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, -0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00],
        [1.4013e-45, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00]])
```  

创建一个随机初始化的矩阵： 

```python
x = torch.rand(5,3)
print(x)
```

输出：

```python
tensor([[0.1633, 0.3415, 0.6341],
        [0.9496, 0.6820, 0.7831],
        [0.2327, 0.0311, 0.6763],
        [0.5513, 0.6381, 0.1251],
        [0.4553, 0.0795, 0.5904]])
```  

创建一个由0填充，数据类型为*long*的矩阵： 

```python
x = torch.zeros(5,3,dtype=torch.long)
print(x)
```

输出：  

```python
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
```    

由给定的数据直接创建一个Tensor：  

```python
x = torch.tensor([5.5,3])
print(x)
```

输出：   

```python
tensor([5.5000, 3.0000])
```  

根据已存在的Tensor创建一个新的Tensor。除非用户提供新值，否则输入的Tensor的属性将被复用：  

```python
x = x.new_ones(5,3,dtype=torch.double)
print(x)

x = torch.randn_like(x,dtype=torch.float)
print(x)
```

输出： 
```python
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
tensor([[-1.2001, -0.3921,  1.1179],
        [-1.5787,  0.4377, -0.2543],
        [-0.2502, -0.4977,  1.1637],
        [ 0.4006,  1.3536,  0.6846],
        [-0.1242,  0.5019, -0.9795]])
```  

获取大小：  

```python
print(x.size())
```

输出： 

```python
torch.Szie([5,3])
```

> troch.Size实际是一个元组，所以支持元组的所有操作。  

#### Operations（操作）  

数学运算有多种语法。在下面的例子中，我们已加法运算为例。  

加法：语法 1  

```python
y = torch.rand(5,3)
print('y = ',y)
print('x + y = ',x+y)
```

输出：  

```python
y =  tensor([[0.2520, 0.5938, 0.5229],
        [0.1242, 0.9339, 0.4859],
        [0.3769, 0.4005, 0.2906],
        [0.4649, 0.2526, 0.7136],
        [0.0941, 0.9550, 0.4462]])
x+y =  tensor([[-0.9482,  0.2017,  1.6408],
        [-1.4545,  1.3715,  0.2317],
        [ 0.1268, -0.0973,  1.4543],
        [ 0.8655,  1.6062,  1.3982],
        [-0.0301,  1.4569, -0.5333]])
```  

加法：语法 2  

```python
print('x+y = ',torch.add(x,y))
```

输出： 

```python
x+y =  tensor([[-0.9482,  0.2017,  1.6408],
        [-1.4545,  1.3715,  0.2317],
        [ 0.1268, -0.0973,  1.4543],
        [ 0.8655,  1.6062,  1.3982],
        [-0.0301,  1.4569, -0.5333]])
```  

加法：提供一个输出的Tensor作为参数：  

```python
result = torch.empty(5,3)
torch.add(x,y,out=result)
print(result)
```

输出：  

```python
tensor([[-0.9482,  0.2017,  1.6408],
        [-1.4545,  1.3715,  0.2317],
        [ 0.1268, -0.0973,  1.4543],
        [ 0.8655,  1.6062,  1.3982],
        [-0.0301,  1.4569, -0.5333]])
```

加法：替代  

```python
y.add_(x)
print(y)
```

输出：  

```python
tensor([[-0.9482,  0.2017,  1.6408],
        [-1.4545,  1.3715,  0.2317],
        [ 0.1268, -0.0973,  1.4543],
        [ 0.8655,  1.6062,  1.3982],
        [-0.0301,  1.4569, -0.5333]])
```

> 任何替换原Tensor的操作都是以“_”为后缀的。例如 `x.copy_(y)`,`x.t_()`，都会改变`x`。  

你可以使用标准的NumPy索引来获取元素：  

```python
print(x)
print(x[:,1])
```

输出：

```python
tensor([[-1.2001, -0.3921,  1.1179],
        [-1.5787,  0.4377, -0.2543],
        [-0.2502, -0.4977,  1.1637],
        [ 0.4006,  1.3536,  0.6846],
        [-0.1242,  0.5019, -0.9795]])
tensor([-0.3921,  0.4377, -0.4977,  1.3536,  0.5019])
```

重置大小：如果你想改变Tensor的大小或者形状，你可以使用`torch.view`：  

```python
x = torch.rand(4,4)
y = x.view(16)
z = x.view(-1,8)   # -1为占位符，其大小是从其它维度推断出来的
print(x.size(),y.size(),z.size())
```

```python
torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])
```  

如果你的Tensor只有一个元素，那么可以使用`.item()`获取到Python数字类型的值：  

```python
x = torch.randn(1)
print(x)
print(x.item())
```

输出： 

```python
tensor([0.6787])
0.678749144077301
```

进阶阅读：  

> 100+向量操作，包括转置、索引、切片、数学运算、线性代数、随机数等，详见[这里](https://pytorch.org/docs/stable/torch.html)  

#### NumPy Bridge  

将一个Torch Tensor转换成NumPy array是非常简单的，反之亦然。转换后的Torch Tensor和NumPy array共享底层的内存地址（如果Torch Tensor在CPU上），即修改一个，另一个也会改变。  

##### 将torch tensor转NumPy array

```python
a = torch.ones(5)
print(a)
```

输出：
```python
tensor([1., 1., 1., 1., 1.])
```

```python
b = a.numpy()
print(b)
```

输出：  

```python
[1. 1. 1. 1. 1.]
```  

tensor值改变，numpy array的值也改变：  

```python
a.add_(1)
print(a)
print(b)
```

输出：  

```python
tensor([2., 2., 2., 2., 2.])
[2. 2. 2. 2. 2.]
```  

##### 将NumPy array 转Torch tensor  

接下来展示如何将NumPy array转换为 Torch tensor  

```python
import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
np.add(a,1,out=a)
print(a)
print(b)
```

输出： 

```python
[2. 2. 2. 2. 2.]
tensor([2., 2., 2., 2., 2.], dtype=torch.float64)
```  

除了CharTensor外，所有CPU上的Tensor都支持转成NumPy array并返回。  

#### CUDA Tensors

Tensors可以使用`.to`方法移动到任何设备上。  

```python
# let us run this cell only if CUDA is available
# We will use ``torch.device`` objects to move tensors in and out of GPU
if torch.cuda.is_available():
    device = torch.device("cuda")          # a CUDA device object
    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU
    x = x.to(device)                       # or just use strings ``.to("cuda")``
    z = x + y
    print(z)
    print(z.to("cpu", torch.double))       # ``.to`` can also change dtype together!
```  

输出：  

```python
tensor([2.0897], device='cuda:0')
tensor([2.0897], dtype=torch.float64)
```  

---

<div align="center">
  <img src="../img/qrcode_wechat.jpg" alt="孟斯特">
</div>

> 声明：本作品采用[署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)进行许可，使用时请注明出处。  
> Author: [mengbin](mengbin1992@outlook.com)  
> blog: [mengbin](https://mengbin.top)  
> Github: [mengbin92](https://mengbin92.github.io/)  
> cnblogs: [恋水无意](https://www.cnblogs.com/lianshuiwuyi/)  

---
